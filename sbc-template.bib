@misc{artigo_base,
  doi = {10.48550/ARXIV.2204.09082},
  
  url = {https://arxiv.org/abs/2204.09082},
  
  author = {Hemmer, Patrick and Schemmer, Max and Riefle, Lara and Rosellen, Nico and Vössing, Michael and Kühl, Niklas},
  
  keywords = {Human-Computer Interaction (cs.HC), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Factors that influence the adoption of human-AI collaboration in clinical decision-making},
  
  publisher = {arXiv},
  
  year = {2022},
  
  copyright = {Creative Commons Attribution Non Commercial No Derivatives 4.0 International}
}

@article{lichtenstein2011sistemas,
  title={Sistemas de apoio {\`a} decis{\~a}o baseados em diretrizes interpretadas por computador: um breve hist{\'o}rico e outros t{\'o}picos},
  author={Lichtenstein, Flavio and Tavares, Agostinho and Pisa, Ivan Torres and Sigulem, Daniel},
  journal={Journal of Health Informatics},
  volume={3},
  number={4},
  year={2011}
}

@inproceedings{NLCP,
author = {Iacob, Radu and Rebedea, Traian and Trausan-Matu, Stefan},
year = {2017},
month = {05},
pages = {252-259},
booktitle={2017 21st International Conference on Control Systems and Computer Science (CSCS)}, 
title={NLCP: Towards a Compiler for Natural Language}, 
doi = {10.1109/CSCS.2017.42}
}

@book{Niklaus,
  added-at = {2015-11-11T17:08:12.000+0100},
  author = {Wirth, Niklaus},
  biburl = {https://www.bibsonomy.org/bibtex/2caa02b75d26fcd4045d8ec860d67729b/jil},
  interhash = {7979586c17d0f0380e2c76e722d3b63a},
  intrahash = {caa02b75d26fcd4045d8ec860d67729b},
  isbn = {978-0-201-40353-6},
  keywords = {book buch compiler compilerbau construction online},
  note = {slightly revised November 2005 version of the book},
  publisher = {Addison-Wesley},
  series = {International computer science series},
  timestamp = {2015-11-11T17:13:39.000+0100},
  title = {Compiler construction},
  url = {http://www.ethoberon.ethz.ch/WirthPubl/CBEAll.pdf},
  year = 1996
}


@article{NLP_book,
author = {Martinez, Angel R.},
title = {Natural language processing},
journal = {WIREs Computational Statistics},
volume = {2},
number = {3},
pages = {352-357},
keywords = {parsing, latent semantic indexing, probabilistic grammars, word sense disambiguation, information retrieval},
doi = {https://doi.org/10.1002/wics.76},
url = {https://wires.onlinelibrary.wiley.com/doi/abs/10.1002/wics.76},
eprint = {https://wires.onlinelibrary.wiley.com/doi/pdf/10.1002/wics.76},
abstract = {Abstract Approximately 40 years ago, the goal of endowing computers with the capacity to understand natural language began. These efforts were originally called natural language understanding, which is now more frequently called natural language processing (NLP). NLP is considered a branch of artificial intelligence (AI), but over the years it has become an interesting area of study in computational statistics and text data mining. NLP encompasses approaches that use computers to analyze, determine semantic similarity, and translate between languages. The area usually deals with written languages, but it could also be applied to speech. In this article, we cover definitions and concepts necessary for the understanding of NLP, methods at the word and sentence level (word sense disambiguation, part-of-speech tagging, and parsing), and the vector space model for NLP at the document level. Copyright © 2010 John Wiley \& Sons, Inc. This article is categorized under: Statistical Learning and Exploratory Methods of the Data Sciences > Text Mining},
year = {2010}
}

@article{NLP_ml_and_protein,
title = {The language of proteins: NLP, machine learning & protein sequences},
journal = {Computational and Structural Biotechnology Journal},
volume = {19},
pages = {1750-1758},
year = {2021},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2021.03.022},
url = {https://www.sciencedirect.com/science/article/pii/S2001037021000945},
author = {Dan Ofer and Nadav Brandes and Michal Linial},
keywords = {Natural language processing, Deep learning, Language models, BERT, Bag of words, Tokenization, Word embedding, Contextualized embedding, Transformer, Artificial neural networks, Word2vec, Bioinformatics},
abstract = {Natural language processing (NLP) is a field of computer science concerned with automated text and language analysis. In recent years, following a series of breakthroughs in deep and machine learning, NLP methods have shown overwhelming progress. Here, we review the success, promise and pitfalls of applying NLP algorithms to the study of proteins. Proteins, which can be represented as strings of amino-acid letters, are a natural fit to many NLP methods. We explore the conceptual similarities and differences between proteins and language, and review a range of protein-related tasks amenable to machine learning. We present methods for encoding the information of proteins as text and analyzing it with NLP methods, reviewing classic concepts such as bag-of-words, k-mers/n-grams and text search, as well as modern techniques such as word embedding, contextualized embedding, deep learning and neural language models. In particular, we focus on recent innovations such as masked language modeling, self-supervised learning and attention-based models. Finally, we discuss trends and challenges in the intersection of NLP and protein research.}
}

@inproceedings{liddy2001natural,
  title={Natural language processing},
  author={Liddy, Elizabeth D},
  year={2001},
  booktitle={Encyclopedia of Library and Information Science},
  
}

@book{bird2009natural,
  title={Natural language processing with Python: analyzing text with the natural language toolkit},
  author={Bird, Steven and Klein, Ewan and Loper, Edward},
  year={2009},
  publisher={" O'Reilly Media, Inc."}
}

%essa é a dissertação de mestrado, não usei ainda
@phdthesis{notas_clinicas,
    title    = {Text Mining e Processamento de Linguagem Natural para Interpretação de Notas Clínicas },
    school   = {Universidade do Minho},
    author   = {António João Oliveira da Silva},
    year     = {2016},
    type     = {{PhD} dissertation},
}

@phdthesis{prontuario_PLN,
    title    = {Aplicação de mineração de texto e processamento de linguagem natural em prontuários eletrônicos de pacientes para extração e transformação de texto em dado estruturado },
    school   = {Universidade Federal do Rio Grande do Norte},
    author   = {Benício, Diego Henrique Pegado},
    year     = {2020},
    type     = {{PhD} dissertation},
}

@article{CDSS_critical_care,
title = {Precision diagnosis: a view of the clinical decision support systems (CDSS) landscape through the lens of critical care},
journal = {Journal of Clinical Monitoring and Computing},
volume = {31},
pages = {261-271},
year = {2017},
issn = {1573-2614},
doi = {10.1007/s10877-016-9849-1},
url = {https://doi.org/10.1007/s10877-016-9849-1},
author = {Arnaud Belard and Timothy Buchman and Jonathan Forsberg and Benjamin K. Potter and Chistopher J. Dente and Allan Kirk and Eric Elster},
keywords = {Clinical decision support systems, CDSS, Healthcare analytics, Critical care, Complex care, Personalized medicine},
abstract = {Improving diagnosis and treatment depends on clinical monitoring and computing. Clinical decision support systems (CDSS) have been in existence for over 50 years. While the literature points to positive impacts on quality and patient safety, outcomes, and the avoidance of medical errors, technical and regulatory challenges continue to retard their rate of integration into clinical care processes and thus delay the refinement of diagnoses towards personalized care. We conducted a systematic review of pertinent articles in the MEDLINE, US Department of Health and Human Services, Agency for Health Research and Quality, and US Food and Drug Administration databases, using a Boolean approach to combine terms germane to the discussion (clinical decision support, tools, systems, critical care, trauma, outcome, cost savings, NSQIP, APACHE, SOFA, ICU, and diagnostics). References were selected on the basis of both temporal and thematic relevance, and subsequently aggregated around four distinct themes: the uses of CDSS in the critical and surgical care settings, clinical insertion challenges, utilization leading to cost-savings, and regulatory concerns. Precision diagnosis is the accurate and timely explanation of each patient’s health problem and further requires communication of that explanation to patients and surrogate decision-makers. Both accuracy and timeliness are essential to critical care, yet computed decision support systems (CDSS) are scarce. The limitation arises from the technical complexity associated with integrating and filtering large data sets from diverse sources. Provider mistrust and resistance coupled with the absence of clear guidance from regulatory bodies further retard acceptance of CDSS. While challenges to develop and deploy CDSS are substantial, the clinical, quality, and economic impacts warrant the effort, especially in disciplines requiring complex decision-making, such as critical and surgical care. Improving diagnosis in health care requires accumulation, validation and transformation of data into actionable information. The aggregate of those processes—CDSS—is currently primitive. Despite technical and regulatory challenges, the apparent clinical and economic utilities of CDSS must lead to greater engagement. These tools play the key role in realizing the vision of a more ‘personalized medicine’, one characterized by individualized precision diagnosis rather than population-based risk-stratification.}
}

@article{WANG201834,
title = {Clinical information extraction applications: A literature review},
journal = {Journal of Biomedical Informatics},
volume = {77},
pages = {34-49},
year = {2018},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2017.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S1532046417302563},
author = {Yanshan Wang and Liwei Wang and Majid Rastegar-Mojarad and Sungrim Moon and Feichen Shen and Naveed Afzal and Sijia Liu and Yuqun Zeng and Saeed Mehrabi and Sunghwan Sohn and Hongfang Liu},
keywords = {Information extraction, Natural language processing, Application, Clinical notes, Electronic health records},
abstract = {Background
With the rapid adoption of electronic health records (EHRs), it is desirable to harvest information and knowledge from EHRs to support automated systems at the point of care and to enable secondary use of EHRs for clinical and translational research. One critical component used to facilitate the secondary use of EHR data is the information extraction (IE) task, which automatically extracts and encodes clinical information from text.
Objectives
In this literature review, we present a review of recent published research on clinical information extraction (IE) applications.
Methods
A literature search was conducted for articles published from January 2009 to September 2016 based on Ovid MEDLINE In-Process & Other Non-Indexed Citations, Ovid MEDLINE, Ovid EMBASE, Scopus, Web of Science, and ACM Digital Library.
Results
A total of 1917 publications were identified for title and abstract screening. Of these publications, 263 articles were selected and discussed in this review in terms of publication venues and data sources, clinical IE tools, methods, and applications in the areas of disease- and drug-related studies, and clinical workflow optimizations.
Conclusions
Clinical IE has been used for a wide range of applications, however, there is a considerable gap between clinical studies using EHR data and studies using clinical IE. This study enabled us to gain a more concrete understanding of the gap and to provide potential solutions to bridge this gap.}
}

@article{what_can_nlp_cdss,
title = {What can natural language processing do for clinical decision support?},
journal = {Journal of Biomedical Informatics},
volume = {42},
number = {5},
pages = {760-772},
year = {2009},
note = {Biomedical Natural Language Processing},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2009.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S1532046409001087},
author = {Dina Demner-Fushman and Wendy W. Chapman and Clement J. McDonald},
keywords = {Natural language processing, Decision support techniques, Clinical decision support systems, Review},
abstract = {Computerized clinical decision support (CDS) aims to aid decision making of health care providers and the public by providing easily accessible health-related information at the point and time it is needed. natural language processing (NLP) is instrumental in using free-text information to drive CDS, representing clinical knowledge and CDS interventions in standardized formats, and leveraging clinical narrative. The early innovative NLP research of clinical narrative was followed by a period of stable research conducted at the major clinical centers and a shift of mainstream interest to biomedical NLP. This review primarily focuses on the recently renewed interest in development of fundamental NLP methods and advances in the NLP systems for CDS. The current solutions to challenges posed by distinct sublanguages, intended user groups, and support goals are discussed.}
}

@INPROCEEDINGS {compiler_natural_language,
author = {R. Iacob and T. Rebedea and S. Trausan-Matu},
booktitle = {2017 21st International Conference on Control Systems and Computer Science (CSCS)},
title = {NLCP: Towards a Compiler for Natural Language},
year = {2017},
volume = {},
issn = {2379-0482},
pages = {252-259},
keywords = {natural languages;computer languages;syntactics;cognition;program processors;algorithm design and analysis;programming},
doi = {10.1109/CSCS.2017.42},
url = {https://doi.ieeecomputersociety.org/10.1109/CSCS.2017.42},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {may}
}

@inproceedings{compiler_on-line_data,
author = {Kellogg, Charles H.},
title = {A Natural Language Compiler for On-Line Data Management},
year = {1968},
isbn = {9781450378994},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1476589.1476654},
doi = {10.1145/1476589.1476654},
abstract = {During the past few years there has been a rapid advance in the technology of time-sharing systems and software to permit quick access to large files of structured data. This has led to a growing interest in communicating with computer files directly in a natural language such as English. The natural language systems described in the literature are largely small-scale research vehicles dealing with small data bases of restricted subject scope. Giuliano (1965), among others, has questioned the generalization of these systems to wider universes of discourse. Developments in this area have been reviewed by Simmons (1966), and by Bobrow, Fraser and Quillan (1967). In contrast, the work in on-line data management has been more concerned with the efficient organization of structured data to allow for quick access and maintenance of large volumes of formatted information [see the reviews by Kellogg (1967), Climenson (1966), and Minker and Sable (1967)].},
booktitle = {Proceedings of the December 9-11, 1968, Fall Joint Computer Conference, Part I},
pages = {473–492},
numpages = {20},
location = {San Francisco, California},
series = {AFIPS '68 (Fall, part I)}
}


@inproceedings{compiler_code_conversion,
author = {Sridhar, Sashank and Sanagavarapu, Sowmya},
year = {2020},
month = {12},
pages = {},
title = {A Compiler-based Approach for Natural Language to Code Conversion},
doi = {10.1109/IC2IE50715.2020.9274674}
}

@article{algorithm_cdss,
title = {Development of an Automated Algorithm to Generate Guideline-based Recommendations for Follow-up Colonoscopy},
journal = {Clinical Gastroenterology and Hepatology},
volume = {18},
number = {9},
pages = {2038-2045.e1},
year = {2020},
issn = {1542-3565},
doi = {https://doi.org/10.1016/j.cgh.2019.10.013},
url = {https://www.sciencedirect.com/science/article/pii/S1542356519311127},
author = {Abhishek Karwa and Rushad Patell and Gopanandan Parthasarathy and Rocio Lopez and John McMichael and Carol A. Burke},
keywords = {USMSTF, Software, Quality Improvement, Management},
abstract = {Background and Aims
Physician adherence to published colonoscopy surveillance guidelines varies. We aimed to develop and validate an automated clinical decision support algorithm that can extract procedure and pathology data from the electronic medical record (EMR) and generate surveillance intervals congruent with guidelines, which might increase physician adherence.
Methods
We constructed a clinical decision support (CDS) algorithm based on guidelines from the United States Multi-Society Task Force on Colorectal Cancer. We used a randomly generated validation dataset of 300 outpatient colonoscopies performed at the Cleveland Clinic from 2012 through 2016 to evaluate the accuracy of extracting data from reports stored in the EMR using natural language processing (NLP). We compared colonoscopy follow-up recommendations from the CDS algorithm, endoscopists, and task force guidelines. Using a testing dataset of 2439 colonoscopies, we compared endoscopist recommendations with those of the algorithm.
Results
Manual review of the validation dataset confirmed the NLP program accurately extracted procedure and pathology data for all cases. Recommendations made by endoscopists and the CDS algorithm were guideline-concordant in 62\% and 99\% of cases, respectively. Discrepant recommendations by endoscopists were earlier than recommended in 94\% of the cases. In the testing dataset, 69\% of endoscopist and NLP-CDS algorithm recommendations were concordant. Discrepant recommendations by endoscopists were earlier than guidelines in 91\% of cases.
Conclusions
We constructed and tested an automated CDS algorithm that can use NLP-extracted data from the EMR to generate follow-up colonoscopy surveillance recommendations based on published guidelines.}
}

@Inbook{nlp_biomedicine_arquitecture,
author="Doan, Son
and Conway, Mike
and Phuong, Tu Minh
and Ohno-Machado, Lucila",
editor="Trent, Ronald",
title="Natural Language Processing in Biomedicine: A Unified System Architecture Overview",
bookTitle="Clinical Bioinformatics",
year="2014",
publisher="Springer New York",
address="New York, NY",
pages="275--294",
abstract="In contemporary electronic medical records much of the clinically important data---signs and symptoms, symptom severity, disease status, etc.---are not provided in structured data fields but rather are encoded in clinician-generated narrative text. Natural language processing (NLP) provides a means of unlocking this important data source for applications in clinical decision support, quality assurance, and public health. This chapter provides an overview of representative NLP systems in biomedicine based on a unified architectural view. A general architecture in an NLP system consists of two main components: background knowledge that includes biomedical knowledge resources and a framework that integrates NLP tools to process text. Systems differ in both components, which we review briefly. Additionally, the challenge facing current research efforts in biomedical NLP includes the paucity of large, publicly available annotated corpora, although initiatives that facilitate data sharing, system evaluation, and collaborative work between researchers in clinical NLP are starting to emerge.",
isbn="978-1-4939-0847-9",
doi="10.1007/978-1-4939-0847-9_16",
url="https://doi.org/10.1007/978-1-4939-0847-9_16"
}

@book{aho86,
  added-at = {2007-03-17T15:34:03.000+0100},
  annote = {Mentions (mostly) viable prefix property. Earlier dragon book is more clear on this. Also mentioned in Graham-Rhodes paper.},
  author = {Aho, Alfred V. and Sethi, Ravi and Ullman, Jeffrey D.},
  biburl = {https://www.bibsonomy.org/bibtex/2540b2a8f4a1fffbbfe439ad1b91247ac/yijunyu},
  citeulike-article-id = {608947},
  interhash = {069cab756cb575510f247044b597377d},
  intrahash = {540b2a8f4a1fffbbfe439ad1b91247ac},
  keywords = {compilation compiler},
  priority = {0},
  publisher = {Addison-Wesley},
  timestamp = {2007-03-17T15:34:11.000+0100},
  title = {{Compilers, Principles, Techniques, and Tools}},
  year = 1986
}


@book{book_compilers,
  added-at = {2007-03-17T15:34:03.000+0100},
  annote = {Mentions (mostly) viable prefix property. Earlier dragon book is more clear on this. Also mentioned in Graham-Rhodes paper.},
  author = {Aho, Alfred V. and Sethi, Ravi and Ullman, Jeffrey D.},
  biburl = {https://www.bibsonomy.org/bibtex/2540b2a8f4a1fffbbfe439ad1b91247ac/yijunyu},
  citeulike-article-id = {608947},
  interhash = {069cab756cb575510f247044b597377d},
  intrahash = {540b2a8f4a1fffbbfe439ad1b91247ac},
  keywords = {compilation compiler},
  priority = {0},
  publisher = {Addison-Wesley},
  timestamp = {2007-03-17T15:34:11.000+0100},
  title = {{Compilers, Principles, Techniques, and Tools}},
  year = 1986
}
